import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from sklearn import preprocessing
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import AdaBoostClassifier
import bisect
import os
from tqdm import tqdm
from xgboost import XGBClassifier
from xgboost import plot_importance
from matplotlib import pyplot


def data_processing():

    if not (os.path.exists('Full_TD.csv') and os.path.exists('TD.csv') and os.path.exists('id.csv')):

        TrainData = pd.read_csv("train.csv")
        #Testdata = pd.read_csv("test.csv")





        Full_TD=TrainData.drop(columns=['MachineIdentifier'])

        #id = Testdata[['MachineIdentifier']]

        #TD = Testdata.drop(columns=['MachineIdentifier'])


        features = Full_TD.columns.tolist()
        features.pop(-1)
        print(len(features))

        tmp_df = Full_TD


        le = preprocessing.LabelEncoder()

        for i in tqdm(features):
            p = 0
            while pd.isna(Full_TD[i][p]):
                p = p+1
                pass

            tmpstr = Full_TD[i].mode()[0]
            Full_TD[i] = Full_TD[i].fillna(tmpstr)
            #TD[i] = TD[i].fillna(tmpstr)


            if type(Full_TD[i][p])==str:
                le.fit(tmp_df[i].astype(str))
                Full_TD[i] = le.transform(Full_TD[i].astype(str))
                #TD[i] = le.transform(TD[i].astype(str))
                pass
            pass
        '''
        Full_TD.to_csv('Full_TD.csv', index = False)
        TD.to_csv('TD.csv', index = False)
        id.to_csv('id.csv', index = False)

        print('Save successfully')
        '''
        pass

    else:
        print('Read processed data')
        Full_TD = pd.read_csv('Full_TD.csv')
        #TD = pd.read_csv('TD.csv')
        #id = pd.read_csv('id.csv')

        features = Full_TD.columns.tolist()
        features.pop(-1)








    return features,Full_TD





if __name__ == '__main__':

    #data pre-processing
    features,Full_TD = data_processing()




    print(Full_TD.shape)

    #set parameters of XGBoost

    other_params = {'learning_rate': 0.1, 'n_estimators': 600, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,
                    'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}



    #set XGBoost model
    model = XGBClassifier(**other_params)

    # split data
    X_tmp, X_rest, Y_tmp, Y_rest = train_test_split(Full_TD[features],Full_TD['HasDetections'],random_state=0,test_size=0.9)
    X_train, X_test, Y_train, Y_test = train_test_split(X_tmp, Y_tmp,random_state=0)


    # get feature importance
    # fig, ax = pyplot.subplots(figsize=(40, 20))
    # plot_importance(model,ax=ax)
    # pyplot.show()

    # feature_import = pd.DataFrame({'features': features, 'value': model.feature_importances_})
    # print(feature_import)


    #CV test to find the best parameter
    ##n_estimators
    cv_params = {'n_estimators': [550, 575, 600, 650, 675]}
    optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)
    optimized_GBM.fit(X_train, Y_train)
    print("best n_estimator:",optimized_GBM.best_params_)

    ##learning_rate
    cv_params ={'learning_rate':[0.01, 0.05, 0.07, 0.1, 0.2]}
    other_params['n_estimators'] = optimized_GBM.best_estimator_
    model = XGBClassifier(**other_params)
    optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)
    optimized_GBM.fit(X_train, Y_train)
    print("best learning_rate:",optimized_GBM.best_estimator_)

    ##max_depth
    cv_params =  {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10]}
    other_params['learning_rate'] = optimized_GBM.best_estimator_
    model = XGBClassifier(**other_params)
    optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)
    optimized_GBM.fit(X_train, Y_train)
    print("best max_depth:", optimized_GBM.best_estimator_)

    #trian the model with best parameters:
    other_params['max_depth'] = optimized_GBM.best_estimator_
    model = XGBClassifier(**other_params)
    model.fit(X_train,Y_train)


    #test model
    pred = model.score(X_test,Y_test)

    print('Accuracy: ',pred)


    pred = model.predict(X_test)

    print('AUC score: ',roc_auc_score(Y_test,pred))


    pass


